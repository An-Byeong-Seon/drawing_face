{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['filename', 'description'], dtype='object')\n",
      "(1050, 2)\n",
      "Index(['filename', 'description', 'h_length', 'h_bang', 'h_curl', 'e_shape',\n",
      "       'f_shape', 'sex', 'nose', 'e_size', 'm_size'],\n",
      "      dtype='object')\n",
      "(350, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "desc = pd.read_csv('./data/NLP_1분반.tsv', sep='\\t', )\n",
    "print(desc.columns)\n",
    "print(desc.shape)\n",
    "\n",
    "feature = pd.read_csv('./data/merged_labels.tsv', sep='\\t', )\n",
    "print(feature.columns)\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.png</td>\n",
       "      <td>She is a Westerner who appears to be in her 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.png</td>\n",
       "      <td>She looks like 30-year-old. She has medium rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.png</td>\n",
       "      <td>She is a middle-aged Western woman. She has ey...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.png</td>\n",
       "      <td>Looking middle-aged, he has grayish brown hair...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.png</td>\n",
       "      <td>He looks like 40-year-old. He has thick flat e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename                                        description\n",
       "0    0.png  She is a Westerner who appears to be in her 30...\n",
       "1    0.png  She looks like 30-year-old. She has medium rou...\n",
       "2    0.png  She is a middle-aged Western woman. She has ey...\n",
       "3    1.png  Looking middle-aged, he has grayish brown hair...\n",
       "4    1.png  He looks like 40-year-old. He has thick flat e..."
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>description</th>\n",
       "      <th>h_length</th>\n",
       "      <th>h_bang</th>\n",
       "      <th>h_curl</th>\n",
       "      <th>e_shape</th>\n",
       "      <th>f_shape</th>\n",
       "      <th>sex</th>\n",
       "      <th>nose</th>\n",
       "      <th>e_size</th>\n",
       "      <th>m_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150.png</td>\n",
       "      <td>She is a middle-aged white woman. Her hair is ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.00</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151.png</td>\n",
       "      <td>He is a middle-aged Asian man. His hair is bla...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.50</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>152.png</td>\n",
       "      <td>He is a middle-aged white man. He has grayish,...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.00</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153.png</td>\n",
       "      <td>He is a white young man. His hair is brown, an...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.75</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154.png</td>\n",
       "      <td>He is a middle-aged white man. He has grayish ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.50</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>345.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.50</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>346.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.25</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>347.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>348.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349.png</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.00</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename                                        description  h_length  \\\n",
       "0    150.png  She is a middle-aged white woman. Her hair is ...       3.0   \n",
       "1    151.png  He is a middle-aged Asian man. His hair is bla...       2.0   \n",
       "2    152.png  He is a middle-aged white man. He has grayish,...       1.0   \n",
       "3    153.png  He is a white young man. His hair is brown, an...       1.0   \n",
       "4    154.png  He is a middle-aged white man. He has grayish ...       1.0   \n",
       "..       ...                                                ...       ...   \n",
       "345  345.png                                                NaN       2.0   \n",
       "346  346.png                                                NaN       2.0   \n",
       "347  347.png                                                NaN       2.0   \n",
       "348  348.png                                                NaN       2.0   \n",
       "349  349.png                                                NaN       2.0   \n",
       "\n",
       "     h_bang  h_curl  e_shape  f_shape  sex  nose  e_size  m_size  \n",
       "0       0.0     1.0      2.0      1.0  0.0   0.0   29.00      33  \n",
       "1       0.0     2.0      2.0      1.0  1.0   0.0   24.50      40  \n",
       "2       0.0     0.0      3.0      0.0  1.0   0.0   23.00      28  \n",
       "3       0.0     2.0      2.0      1.0  1.0   0.0   28.75      39  \n",
       "4       0.0     1.0      2.0      1.0  1.0   0.0   34.50      31  \n",
       "..      ...     ...      ...      ...  ...   ...     ...     ...  \n",
       "345     2.0     0.0      2.0      1.0  0.0   0.0   30.50      39  \n",
       "346     0.0     1.0      3.0      1.0  1.0   0.0   21.25      29  \n",
       "347     0.0     0.0      2.0      2.0  0.0   0.0   20.00      38  \n",
       "348     0.0     1.0      2.0      0.0  1.0   1.0   31.00      42  \n",
       "349     2.0     0.0      2.0      0.0  0.0   0.0   35.00      41  \n",
       "\n",
       "[350 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = feature.loc[:, ['filename', 'h_length', 'h_bang', 'h_curl', 'e_shape', 'f_shape', 'sex', 'nose', 'e_size', 'm_size']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_length = pd.merge(desc, df_labels.loc[:,['filename', 'h_length']], on = 'filename', how = 'outer')\n",
    "h_bang = pd.merge(desc, df_labels.loc[:,['filename', 'h_bang']], on = 'filename', how = 'outer')\n",
    "h_curl = pd.merge(desc, df_labels.loc[:,['filename', 'h_curl']], on = 'filename', how = 'outer')\n",
    "e_shape = pd.merge(desc, df_labels.loc[:,['filename', 'e_shape']], on = 'filename', how = 'outer')\n",
    "f_shape = pd.merge(desc, df_labels.loc[:,['filename', 'f_shape']], on = 'filename', how = 'outer')\n",
    "sex = pd.merge(desc, df_labels.loc[:,['filename', 'sex']], on = 'filename', how = 'outer')\n",
    "nose = pd.merge(desc, df_labels.loc[:,['filename', 'nose']], on = 'filename', how = 'outer')\n",
    "e_size = pd.merge(desc, df_labels.loc[:,['filename', 'e_size']], on = 'filename', how = 'outer')\n",
    "m_size = pd.merge(desc, df_labels.loc[:,['filename', 'm_size']], on = 'filename', how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_length = h_length.drop(['filename'], axis=1)\n",
    "h_bang = h_bang.drop(['filename'], axis=1)\n",
    "h_curl = h_curl.drop(['filename'], axis=1)\n",
    "e_shape = e_shape.drop(['filename'], axis=1)\n",
    "f_shape = f_shape.drop(['filename'], axis=1)\n",
    "sex = sex.drop(['filename'], axis=1)\n",
    "nose = nose.drop(['filename'], axis=1)\n",
    "e_size = e_size.drop(['filename'], axis=1)\n",
    "m_size = m_size.drop(['filename'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_length.to_csv('./data/h_length.tsv', header=False, index=False, sep='\\t')\n",
    "h_bang.to_csv('./data/h_bang.tsv', header=False, index=False, sep='\\t')\n",
    "h_curl.to_csv('./data/h_curl.tsv', header=False, index=False, sep='\\t')\n",
    "e_shape.to_csv('./data/e_shape.tsv', header=False, index=False, sep='\\t')\n",
    "f_shape.to_csv('./data/f_shape.tsv', header=False, index=False, sep='\\t')\n",
    "sex.to_csv('./data/sex.tsv', header=False, index=False, sep='\\t')\n",
    "nose.to_csv('./data/nose.tsv', header=False, index=False, sep='\\t')\n",
    "e_size.to_csv('./data/e_size.tsv', header=False, index=False, sep='\\t')\n",
    "m_size.to_csv('./data/m_size.tsv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 처리하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/e_shape.tsv',\n",
       " './data/e_size.tsv',\n",
       " './data/f_shape.tsv',\n",
       " './data/h_bang.tsv',\n",
       " './data/h_curl.tsv',\n",
       " './data/h_length.tsv',\n",
       " './data/m_size.tsv',\n",
       " './data/nose.tsv',\n",
       " './data/sex.tsv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "data_files = [f.replace(\"\\\\\", \"/\") for f in glob.glob(\"./data/*.tsv\")]\n",
    "data_files.remove('./data/merged_labels.tsv')\n",
    "data_files.remove( './data/NLP_1분반.tsv')\n",
    "data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_ = pd.read_csv(data_files[0], header=None, sep='\\t', ).rename(columns={0: 'desc', 1: 'label'})\n",
    "df = df_.astype({'desc': object, 'label': int})\n",
    "print(df.columns)\n",
    "print(df.shape)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>She is a Westerner who appears to be in her 30...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>She looks like 30-year-old. She has medium rou...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She is a middle-aged Western woman. She has ey...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Looking middle-aged, he has grayish brown hair...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He looks like 40-year-old. He has thick flat e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc  label\n",
       "0  She is a Westerner who appears to be in her 30...      2\n",
       "1  She looks like 30-year-old. She has medium rou...      2\n",
       "2  She is a middle-aged Western woman. She has ey...      2\n",
       "3  Looking middle-aged, he has grayish brown hair...      1\n",
       "4  He looks like 40-year-old. He has thick flat e...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>desc</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>He looks like mid to late 30s. His eyebrows ar...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He is a western baby. He had grayish brown sho...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>She appears to be in her mid-30s. She had thic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He is an Asian boy. He has straight short hair...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>He is a middle and late man. He has deep eyes ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                desc  label\n",
       "0  He looks like mid to late 30s. His eyebrows ar...      3\n",
       "1  He is a western baby. He had grayish brown sho...      2\n",
       "2  She appears to be in her mid-30s. She had thic...      2\n",
       "3  He is an Asian boy. He has straight short hair...      0\n",
       "4  He is a middle and late man. He has deep eyes ...      1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#셔플\n",
    "df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index for train: 0~945\n",
      "index for test: 945~1049\n"
     ]
    }
   ],
   "source": [
    "# train:test = 9:1\n",
    "train_ratio = 0.9\n",
    "\n",
    "# train dataset\n",
    "s, e = 0, int(df_shuffled.shape[0]*train_ratio) # # of rows\n",
    "df_shuffled_label = df_shuffled['label'][s:e]\n",
    "df_shuffled_desc = df_shuffled['desc'][s:e]\n",
    "df_train = pd.DataFrame({'label':df_shuffled_label, 'desc':df_shuffled_desc})\n",
    "print(\"index for train: %d~%d\" %(s, e))\n",
    "\n",
    "#test dataset\n",
    "# train dataset\n",
    "s, e = e, e+int(df_shuffled.shape[0]*(1.0-train_ratio)) # # of rows\n",
    "df_shuffled_label = df_shuffled['label'][s:e]\n",
    "df_shuffled_desc = df_shuffled['desc'][s:e]\n",
    "df_test = pd.DataFrame({'label':df_shuffled_label, 'desc':df_shuffled_desc})\n",
    "print(\"index for test: %d~%d\" %(s, e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(945, 2)\n",
      "(104, 2)\n"
     ]
    }
   ],
   "source": [
    "# column 수 확인\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('./preprocessed_data/'+data_files[0].split('/')[-1].split('.')[0]+'_train.tsv', header=False, index=False, sep='\\t')\n",
    "df_test.to_csv('./preprocessed_data/'+data_files[0].split('/')[-1].split('.')[0]+'_test.tsv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['e_shape', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n",
      "['e_size', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n",
      "['f_shape', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n",
      "['h_bang', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n",
      "['h_curl', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n",
      "['h_length', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n",
      "['m_size', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n",
      "['nose', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n",
      "['sex', 'tsv']\n",
      "Index(['desc', 'label'], dtype='object')\n",
      "(1050, 2)\n",
      "desc     object\n",
      "label     int32\n",
      "dtype: object\n",
      "index for train: 0~945\n",
      "index for test: 945~1049\n"
     ]
    }
   ],
   "source": [
    "for f in data_files:\n",
    "\n",
    "    df_ = pd.read_csv(f, header=None, sep='\\t', ).rename(columns={0: 'desc', 1: 'label'})\n",
    "    df = df_.astype({'desc': object, 'label': int})\n",
    "    print(f.split('/')[-1].split('.'))\n",
    "    print(df.columns)\n",
    "    print(df.shape)\n",
    "    print(df.dtypes)\n",
    "\n",
    "    #셔플\n",
    "    df_shuffled = df.sample(frac=1).reset_index(drop=True)\n",
    "    df_shuffled.head()\n",
    "\n",
    "    # train:test = 9:1\n",
    "    train_ratio = 0.9\n",
    "\n",
    "    # train dataset\n",
    "    s, e = 0, int(df_shuffled.shape[0]*train_ratio) # # of rows\n",
    "    df_shuffled_label = df_shuffled['label'][s:e]\n",
    "    df_shuffled_desc = df_shuffled['desc'][s:e]\n",
    "    df_train = pd.DataFrame({'label':df_shuffled_label, 'desc':df_shuffled_desc})\n",
    "    print(\"index for train: %d~%d\" %(s, e))\n",
    "\n",
    "    #test dataset\n",
    "    # train dataset\n",
    "    s, e = e, e+int(df_shuffled.shape[0]*(1.0-train_ratio)) # # of rows\n",
    "    df_shuffled_label = df_shuffled['label'][s:e]\n",
    "    df_shuffled_desc = df_shuffled['desc'][s:e]\n",
    "    df_test = pd.DataFrame({'label':df_shuffled_label, 'desc':df_shuffled_desc})\n",
    "    print(\"index for test: %d~%d\" %(s, e))\n",
    "\n",
    "    df_train.to_csv('./preprocessed_data/'+f.split('/')[-1].split('.')[0]+'_train.tsv', header=False, index=False, sep='\\t')\n",
    "    df_test.to_csv('./preprocessed_data/'+f.split('/')[-1].split('.')[0]+'_test.tsv', header=False, index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "train_datas = [f.replace(\"\\\\\", \"/\") for f in glob.glob(\"./preprocessed_data/*_train.tsv\")]\n",
    "test_datas = [f.replace(\"\\\\\", \"/\") for f in glob.glob(\"./preprocessed_data/*_test.tsv\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_loader import DataLoader # data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "dropout_p = 0.3\n",
    "word_vec_size = 256 # emb_size\n",
    "\n",
    "hidden_size = 512\n",
    "num_layers = 4\n",
    "\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "learning_rate = 0.001 # 교수님께서 추가\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_datas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-fb27d1c2ead7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m loaders = DataLoader(\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mtrain_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_datas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mvalid_ratio\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# train:val = 8:2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mmax_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m999999\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# 크게\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_datas' is not defined"
     ]
    }
   ],
   "source": [
    "loaders = DataLoader(\n",
    "        train_fn=train_datas[0],\n",
    "        batch_size=batch_size,\n",
    "        valid_ratio=.2, # train:val = 8:2\n",
    "        max_vocab=999999, # 크게\n",
    "        min_freq=5, # 문장의 최소 단어 개수\n",
    ")\n",
    "\n",
    "test_loaders = DataLoader(\n",
    "        train_fn=test_datas[0],\n",
    "        batch_size=batch_size,\n",
    "        valid_ratio=.01, # val 안 나눈다. 0은 안 받으므로 0.01\n",
    "        max_vocab=999999,\n",
    "        min_freq=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-7d669273f39c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m print(\"|train| =\", len(loaders.train_loader.dataset),\n\u001b[0m\u001b[0;32m      2\u001b[0m       \"|valid| =\", len(loaders.valid_loader.dataset))\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvocab_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loaders' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"|train| =\", len(loaders.train_loader.dataset),\n",
    "      \"|valid| =\", len(loaders.valid_loader.dataset))\n",
    "\n",
    "vocab_size = len(loaders.text.vocab)\n",
    "num_classes = len(loaders.label.vocab)\n",
    "print(\"|vocab| =\", vocab_size, \"|classes| =\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "한 번에 로드되는 데이터 크기:  128\n",
      "label:  0\n",
      "text:  (84,)\n",
      "label:  0\n",
      "text:  (84,)\n",
      "label:  0\n",
      "text:  (84,)\n",
      "[1]\n",
      "한 번에 로드되는 데이터 크기:  128\n",
      "label:  0\n",
      "text:  (70,)\n",
      "label:  3\n",
      "text:  (70,)\n",
      "label:  0\n",
      "text:  (70,)\n",
      "[2]\n",
      "한 번에 로드되는 데이터 크기:  128\n",
      "label:  0\n",
      "text:  (62,)\n",
      "label:  3\n",
      "text:  (62,)\n",
      "label:  0\n",
      "text:  (62,)\n",
      "[3]\n",
      "한 번에 로드되는 데이터 크기:  128\n",
      "label:  0\n",
      "text:  (103,)\n",
      "label:  0\n",
      "text:  (103,)\n",
      "label:  0\n",
      "text:  (103,)\n"
     ]
    }
   ],
   "source": [
    "n = 3 # 샘플로 그려볼 데이터 개수\n",
    "for i, data in enumerate(loaders.train_loader): # batch_size 만큼\n",
    "    labels = data.label\n",
    "    texts = data.text\n",
    "    \n",
    "    if i>n:\n",
    "        break\n",
    "    print (\"[%d]\" %i)\n",
    "    print(\"한 번에 로드되는 데이터 크기: \", len(labels))\n",
    "    \n",
    "    # 출력\n",
    "    for j in range(n):\n",
    "        label = labels[j].numpy() # tensor -> numpy로 변환\n",
    "        text = texts[j].numpy()\n",
    "        print(\"label: \", label)\n",
    "        print(\"text: \", text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recurrent neural network (many-to-one)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size, # vocab_size\n",
    "                 word_vec_size, # word embbeding vector 차원\n",
    "                 hidden_size, # bidirectional LSRM의 hidden state & cell state의 size\n",
    "                 n_classes,\n",
    "                 num_layers=4, # 쌓을 레이어 개수\n",
    "                 dropout_p=0.3\n",
    "                 ):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.word_vec_size = word_vec_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_classes = n_classes\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        \n",
    "        # 입력 차원(vocab_size), 출력 차원(word_vec_size)\n",
    "        self.emb =nn.Embedding(input_size, word_vec_size) # 부터!\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=word_vec_size,\n",
    "                            hidden_size=hidden_size,\n",
    "                            num_layers=num_layers,\n",
    "                            dropout=dropout_p,\n",
    "                            batch_first=True,\n",
    "                            bidirectional=True)\n",
    "        self.fc  = nn.Linear(hidden_size*2, n_classes)\n",
    "        # LogSoftmax + NLLLoss instead of Softmax + CrossEntropy\n",
    "        self.activation = nn.LogSoftmax(dim=1) # 마지막 차원에 softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch_size, length)\n",
    "        x = self.emb(x)\n",
    "        \n",
    "        # x: (batch_size, length, word_vec_size)\n",
    "        x, _ = self.lstm(x) # x: output, _: 마지막 time step의 hidden state & cell state\n",
    "        \n",
    "        # x: (batch_size, length, hidden_size*2)\n",
    "        # x[:,-1]: (batch_size, 1, hidden_size*2)\n",
    "        out = self.activation(self.fc(x[:,-1])) # 마지막 time step\n",
    "        # self.fc(x[:,-1]): (batch_size, num_classes)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bcef0f68df04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model = RNN(input_size=vocab_size,\n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0mword_vec_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_vec_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mhidden_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mnum_layers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "model = RNN(input_size=vocab_size,\n",
    "            word_vec_size=word_vec_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            n_classes=num_classes,\n",
    "            dropout_p=dropout_p).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ComputeAccr(dloader, imodel):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    imodel.eval() # test mode\n",
    "    for i, data in enumerate(dloader): # batch_size만큼\n",
    "        texts = data.text.to(device) # (batch_size, length)\n",
    "        labels = data.label.to(device) # (batch_size, num_classes)\n",
    "        \n",
    "        # Forward prop.\n",
    "        output = imodel(texts) # (batch_size, num_classes)\n",
    "        _, output_index = torch.max(output, 1) # (batch_size, 1)\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        \n",
    "        correct += (output_index == labels).sum().float()\n",
    "        # print(\"Accuracy of Test Data: {}\".format(100*correct/total))\n",
    "    \n",
    "    imodel.train()\n",
    "    return (100*correct/total).numpy() # tensor -> numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 10.05\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Data: %.2f\" %ComputeAccr(loaders.valid_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "#loss_func = nn.CrossEntropyLoss()\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n",
      "[2]\n",
      "[3]\n",
      "[4]\n",
      "[5]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-eaceb6cae65a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;31m# Forward prop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (batch_size, num_classes)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DSP\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-297ce7292e19>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# x: (batch_size, length, word_vec_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# x: output, _: 마지막 time step의 hidden state & cell state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;31m# x: (batch_size, length, hidden_size*2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DSP\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\DSP\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 692\u001b[1;33m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    693\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(loaders.train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(loaders.train_loader): # batch_size만큼\n",
    "        texts = data.text.to(device) # (batch_size, length)\n",
    "        labels = data.label.to(device) # (batch_size, num_classes)\n",
    "        \n",
    "        print(\"[%d]\" %i)\n",
    "        \n",
    "        # Forward prop.\n",
    "        output = model(texts) # (batch_size, num_classes)\n",
    "        loss = loss_func(output, labels)\n",
    "        \n",
    "        # Backward prop. & optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch[{}/{}], Step [{}/{}], Loss: {:.4f}, Accr: {:.2f}'\n",
    "                 .format(epoch+1, num_epochs, i+1, total_step,\n",
    "                        loss.item(),\n",
    "                        ComputeAccr(loaders.valid_loader, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test Data: 69.90\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of Test Data: %.2f\" %ComputeAccr(test_loaders.train_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f5c640db9845>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnetname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./nets/rnn_weight_face.pkl'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnetname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "netname = './nets/rnn_weight_face.pkl'\n",
    "torch.save(model, netname, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --train-data \"./preprocessed_data/sex_train.tsv\" --test-data \"./preprocessed_data/sex_test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_shapeAccuracy of Test Data: 69.90\n",
      "f_shapeAccuracy of Test Data: 40.78\n",
      "h_bangAccuracy of Test Data: 72.82\n",
      "h_curlAccuracy of Test Data: 52.43\n",
      "h_lengthAccuracy of Test Data: 47.57\n",
      "noseAccuracy of Test Data: 88.35\n",
      "sexAccuracy of Test Data: 90.29\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from data_loader import DataLoader # data_loader.py\n",
    "weights= glob.glob(\"./nets/*.pkl\")\n",
    "for w in weights:\n",
    "        f = w.split(\"weight_\")[1].split('.')[0].split(' ')[0]\n",
    "        test_loaders = DataLoader(\n",
    "                train_fn=\"./preprocessed_data/\"+f+\"_test.tsv\",\n",
    "                batch_size=batch_size,\n",
    "                valid_ratio=.01, # val 안 나눈다. 0은 안 받으므로 0.01\n",
    "                max_vocab=999999,\n",
    "                min_freq=5,\n",
    "        )\n",
    "        \n",
    "        vocab_size = len(test_loaders.text.vocab)\n",
    "        num_classes = len(test_loaders.label.vocab)\n",
    "        \n",
    "        model = RNN(input_size=vocab_size,\n",
    "            word_vec_size=word_vec_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            n_classes=num_classes,\n",
    "            dropout_p=dropout_p).to(device)\n",
    "        model = torch.load(w, map_location=torch.device('cpu'))\n",
    "        print(f+\"Accuracy of Test Data: %.2f\" %ComputeAccr(test_loaders.train_loader, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./nets\\\\rnn_weight_e_shape.pkl',\n",
       " './nets\\\\rnn_weight_f_shape.pkl',\n",
       " './nets\\\\rnn_weight_h_bang.pkl',\n",
       " './nets\\\\rnn_weight_h_curl.pkl',\n",
       " './nets\\\\rnn_weight_h_length.pkl',\n",
       " './nets\\\\rnn_weight_nose.pkl',\n",
       " './nets\\\\rnn_weight_sex.pkl']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from data_loader import PredDataLoader # data_loader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD_VEC_SIZE = 256\n",
    "HIDDEN_SIZE = 512\n",
    "NUM_LAYERS = 4\n",
    "BATCH_SIZE = 1\n",
    "def predict1(weight_path, text):\n",
    "\n",
    "    vocab_size = len(text.replace(\".\", \" \").split(\" \"))\n",
    "\n",
    "    feature = weight_path.split(\"weight_\")[1].split('.')[0]\n",
    "    classes = {\"h_length\": 4, \"h_bang\": 3, \"h_curl\": 3, \"e_shape\": 4, \"f_shape\": 4, \"sex\": 2, \"nose\": 2}\n",
    "    num_classes = classes[feature]\n",
    "\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    f = open(text.replace(\" \", \"_\"), \"w\")\n",
    "    f.write(\"0\\t\" + text )\n",
    "    f.close()\n",
    "\n",
    "    loaders = PredDataLoader(\n",
    "            train_fn='./testdata/test',\n",
    "            batch_size=BATCH_SIZE,\n",
    "            max_vocab=999999, # 크게\n",
    "            min_freq=5, # 문장의 최소 단어 개수\n",
    "        )\n",
    "    \n",
    "    model = RNN(input_size=vocab_size,\n",
    "            word_vec_size=WORD_VEC_SIZE,\n",
    "            hidden_size=HIDDEN_SIZE,\n",
    "            num_layers=NUM_LAYERS,\n",
    "            n_classes=num_classes).to(device)\n",
    "\n",
    "    model = torch.load(weight_path, map_location=device)\n",
    "    print(loaders.valid_loader)\n",
    "    for i, data in enumerate(loaders.valid_loader): # batch_size만큼\n",
    "            texts = data.text.to(device) # (batch_size, length)\n",
    "\n",
    "            # Forward prop.\n",
    "            output = model(texts) # (batch_size, num_classes)\n",
    "            \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<torchtext.data.iterator.BucketIterator object at 0x00000202367C4EF0>,)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BucketIterator' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-bf5872f34e73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./nets/rnn_weight_sex.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"she is a cute girl.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-40b0db28afa8>\u001b[0m in \u001b[0;36mpredict1\u001b[1;34m(weight_path, text)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# batch_size만큼\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (batch_size, length)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;31m# Forward prop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'BucketIterator' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "predict1('./nets/rnn_weight_sex.pkl', \"she is a cute girl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import predict\n",
    "\n",
    "predict('./nets/rnn_weight_sex.pkl', \"she is a cute girl.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bbd32cdaf1533d3d37157a53c5da7a2af672d0f20c5c120f82b017c2f56bab3d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
